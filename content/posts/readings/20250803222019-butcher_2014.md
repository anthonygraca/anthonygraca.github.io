+++
title = "butcher-2014"
author = ["Anthony Graca"]
date = 2025-08-03T22:20:00-07:00
tags = ["Bibliography"]
draft = false
+++

## Citation {#citation}

```tex
@book{butcher2014,
  title={Seven Concurrency Models in Seven Weeks: When Threads Unravel},
  author={Butcher, Paul},
  year={2014},
  publisher={The Pragmatic Bookshelf}
}
```


## Summary. What are the statements being made? {#summary-dot-what-are-the-statements-being-made}


## 1. Introduction {#1-dot-introduction}


### Concurrent or Parallel? {#concurrent-or-parallel}

-   Concurrent and parallel refer to two related but different things
-   "A _concurrent_ program has multiple logical _threads of control_. These threads may or may not run in parallel (Butcher 2014, 1)."
    -   Concurrency is an aspect of the problem domain, meaning your algorithm needs to handle simultaneous events
    -   "Concurrency is about dealing with lots of things at once - rob pike"
-   "A _parallel_ program potentially runs more quickly than a sequential program by executing different parts of the computation simultaneously in parallel. It may or may not have more than one logical thread of control"
    -   Parallelism is an aspect of the solution domain, meaning you want to make your program faster
    -   "Parallelism is about doing lots of things at once - rob pike"
-   Traditional threads and locks don't provide any direct support for parallelism.
    -   In order to exploit multiple cores with threads and locks, you need to create a concurrent program and then run it on parallel hardware.
    -   This is problematic because concurrent programs are nondeterministic but parallel programs are usually not


### Parallel Architecture {#parallel-architecture}

-   There are multiple levels of parallelism
    -   Moving from 8-bits to 32-bits is a form of _Bit-Level Parallelism_. Adding two 32-bit numbers in a 8-bit architecture would take multiple steps. Doing this operation in a 32-bit system is done in a single step
    -   CPU architectures use pipeling, out-of-order execution, and speculative execution to obtain instruction _instruction-level parallelism_
    -   Data-parallelism is achieved by applying the same operations to a large amount of data in parallel. Imagine increasing the brightness of an image where each pixel easily handled by a GPU
-   What we are interested in is **Task-Level Parallelism**
    -   There are two models of multiprocessor architectures:
        1.  Shared-memory :: where each processor can access any memory location and interprocess communication is done through memory
        2.  Distributed memory :: where each processor has its own local memory and IPC is done via the network.


### Concurrency: Beyond Multiple Cores {#concurrency-beyond-multiple-cores}

-   Concurrency is key to software being responsive, fault tolerant, efficient, and simple


#### Responsive {#responsive}

-   the world is concurrent so software should be concurrent to interact with it properly
-   Examples:
    1.  a mobile phone can play music, talk to the network, and pay attention to touch gestures all at the same time
    2.  an IDE checks for syntax in the background while code is being typed
    3.  A flight system simultaneously monitors sensors, displays information to the pilot, obeys commands, and moves control surfaces
        -   i think of [douglass-2003]({{< relref "20230330175118-douglass_2003.md" >}})
-   Concurrency is key to _responsive_ systems.
    -   Doing things in the background avoids forcing users to wait and stare at a loading screen.


#### Fault Tolerant {#fault-tolerant}

-   Distributed systems are fault tolerant. Shutdown on one data center doesn't halt the entire system
-   Concurrency also enables _fault detection_.
    -   A task that fails can notify a separate task to perform remedial action.
    -   Sequential software can never be as resilient as concurrent software.


#### Simple {#simple}

-   Threading bugs are difficult to diagnose.
-   Concurrent solutions can be simpler and clearer than its sequential equivalent
    -   Translating a concurrent real-world problem to its sequential solution hides detail and requires more work


### The Seven Models {#the-seven-models}

1.  Threads and locks
2.  Functional programming
    -   eliminates mutable state so functional programs are intrinsically thread-safe
3.  The Clojure Way - Separating identity and state
4.  Actors
    -   Concurrent programming model with strong support for fault tolerance and resilence
5.  Communicating Sequential Processes
    -   Emphasizes channels for communication
6.  Data Parallelism - Using GPUs
7.  The Lambda Architecture
    -   Big data with MapReduce and stream processing to handle terabytes of data


## 2. Threads and Locks {#2-dot-threads-and-locks}

-   "Threads-and-locks programming is like a Ford Model T. It will get you from point A to point B, but it is primitive, difficult to drive, and both unreliable and dangerous compared to newer technology (Butcher 2014, 9).


### The Simplest Thing that Could Possibly Work {#the-simplest-thing-that-could-possibly-work}

-   Threads and locks are little more than a formalization of what the underlying hardware actually does.
    -   similar idea to pointers and goto statements


### Day 1: Mutual Exclusion and Memory Models {#day-1-mutual-exclusion-and-memory-models}

Mutual exclusion
: Using locks to ensure that only one thread can access data at a time.
    -   usage avoids race conditions and deadlocks


#### Creating a thread {#creating-a-thread}

```java
public class HelloWorld {
  public static void main(String[] args) throws InterruptedException {
    Thread myTrhead = new Thread() {
        public void run() {
          System.out.println("Hello from new thread");
        }
      };
    myThread.start();
    Thread.yield(); // necessary since myThread has some start time
    System.out.println("Hello from main thread");
    myThread.join();
  }
}
```


#### Our First Lock {#our-first-lock}

-   We can try to create 2 threads to count to 10,000 however the code below encounters issues
    -   Instead of the expected output of 20,000 we see two behaviors
        1.  Result is always some number below what we expect
        2.  Result is always different
    -   This is caused by a _race condition_ when two threads call `increment()` simultaneously
        -   when two threads read `count` at the same time and write at the same time, we encounter a case where the same value is incremented

<!--listend-->

```java
public class Counting {
  public static void main(String[] args) throws InterruptedException {
    class Counter {
      private int count = 0;
      public void increment() { ++count; }
      public int getCount() { return count; }
    }
    final Counter counter = new Counter();
    class CountingThread extends Thread {
      public void run() {
        for (int x = 0; x < 10000; ++x) {
           counter.increment();
        }
      }
    }

    CountingThread t1 = new CountingThread();
    CountingThread t2 = new CountingThread();
    t1.start(); t2.start();
    t1.join(); t2.join();
    System.out.println(counter.getCount());
  }
}
```

-   The solution is to _synchronize_ access to `count` by using java's intrinsic lock
    -   This means whenever `increment()` is called, it claims the `Counter` object's lock so that when another thread tries to access it, it is blocked until the lock is free.
    -   this leads to the correct output of 20,000

<!--listend-->

```java
public class Counting {
  public static void main(String[] args) throws InterruptedException {
    class Counter {
      private int count = 0;
      public synchronized void increment() { ++count; }
      public int getCount() { return count; }
    }
    final Counter counter = new Counter();
    class CountingThread extends Thread {
      public void run() {
        for (int x = 0; x < 10000; ++x) {
           counter.increment();
        }
      }
    }

    CountingThread t1 = new CountingThread();
    CountingThread t2 = new CountingThread();
    t1.start(); t2.start();
    t1.join(); t2.join();
    System.out.println(counter.getCount());
  }
}
```


#### Issue 1: Race Conditions {#issue-1-race-conditions}


#### Issue 2: Memory Visibility {#issue-2-memory-visibility}


#### Issue 3: Deadlock {#issue-3-deadlock}


### Day 2: Beyond Intrinsic Locks {#day-2-beyond-intrinsic-locks}


### Day 3: On the Shoulders of Giants {#day-3-on-the-shoulders-of-giants}


## 3. Functional Programming {#3-dot-functional-programming}

-   p 49


### If it Hurts, Stop Doing It {#if-it-hurts-stop-doing-it}


### Day 1: Programming Without Mutable State {#day-1-programming-without-mutable-state}


### Day 2: Functional Parallelism {#day-2-functional-parallelism}


### Day 3: Functional Concurrency {#day-3-functional-concurrency}


## 4. The Clojure Way - Separating Identity from State {#4-dot-the-clojure-way-separating-identity-from-state}

-   p 85


### The Best of Both Worlds {#the-best-of-both-worlds}


### Day 1: Atoms and Persistent Data Structures {#day-1-atoms-and-persistent-data-structures}


### Day 2: Agents and Software Transactional memory {#day-2-agents-and-software-transactional-memory}


### Day 3: In Depth {#day-3-in-depth}


## 5. Actors {#5-dot-actors}

-   p 115


### More Object-Oriented than Objects {#more-object-oriented-than-objects}


### Day 1: Messages and Mailboxes {#day-1-messages-and-mailboxes}


### Day 2: Error Handling and Resilience {#day-2-error-handling-and-resilience}


### Day 3: Distribution {#day-3-distribution}


## 6. Communicating Sequential Processes {#6-dot-communicating-sequential-processes}

-   p 153


### Communication Is Everything {#communication-is-everything}


### Day 1: Channels and Go Blocks {#day-1-channels-and-go-blocks}


### Day 2: Multiple Channels and IO {#day-2-multiple-channels-and-io}


### Day 3: Client-Side CSP {#day-3-client-side-csp}


## 7. Data Parallelism {#7-dot-data-parallelism}

-   p 189


### The Supercomputer Hidden in Your Laptop {#the-supercomputer-hidden-in-your-laptop}


### Day 1: GPGPU Programming {#day-1-gpgpu-programming}


### Day 2: multiple Dimensions and Work-Groups {#day-2-multiple-dimensions-and-work-groups}


### Day 3: OpenCL and OpenGL - Keeping it on the GPU {#day-3-opencl-and-opengl-keeping-it-on-the-gpu}


## 8. The Lambda Architecture {#8-dot-the-lambda-architecture}

-   p 223


### Parallelism Enables Big Data {#parallelism-enables-big-data}


### Day 1: MapReduce {#day-1-mapreduce}


### Day 2: The Batch Layer {#day-2-the-batch-layer}


### Day 3: The Speed Layer {#day-3-the-speed-layer}


## 9. Wrapping Up {#9-dot-wrapping-up}

-   p 263


## Next {#next}

-   [hoare-1978]({{< relref "article/20240911150404-hoare_1978.md" >}}) - CSP
-   A theory of communicating sequential processes - 1984
-   Carl Hewitt Actor Model - Every object is a process
    -   Hewitt 1973 - A Universal Modular Actor Formalism for Artificial Intelligence
    -   [sicp]({{< relref "20231221093946-abelson_sussman_1996.md" >}})
-   Communicating and Mobile Systems: The Ï€-Calculus by Robin Milner
    -   milner 1989 - every function is a process - task oriented

-   [tate-2010]({{< relref "20250803223046-tate_2010.md" >}})
-   [herlihy-2020]({{< relref "20250804113206-herlihy_2020.md" >}})

-   [douglass-2003]({{< relref "20230330175118-douglass_2003.md" >}})
-   [williams-2019]({{< relref "20230112115043-williams_2019.md" >}})

-   [dean-ghemawat-2008]({{< relref "article/20240921135242-dean_ghemawat_2008.md" >}})
